\section{Security}

HTTP/2 has a number of features which are designed to make it more difficult for an attacker to decrypt the communications between a browser and web server. As with HTTP/1.1, if secure communication is negotiated between the client and the server, the encryption and decryption is handled by a separate protocol called `TLS' (Transport Layer Security)\footnote{Formerly known as `SSL' (Secure Sockets Layer).}. Much like HTTP/1.1, HTTP/2 permits transmission over unencrypted cleartext (called `\texttt{h2c}' when sending HTTP/2 traffic) or transmission over TLS (called `\texttt{h2}' when sending HTTP/2 traffic)~\cite[\S~3.1]{h2}. Currently however, \texttt{h2c} is not supported by major browsers, meaning that TLS is a \textit{de facto} requirement~\cite{tlsh2support}. Of the 2.8 million most popular websites, only 1210 of them had true \texttt{h2c} support~\cite{isthewebhttp2yet} as of November 2016. Since setting up TLS is relatively complicated, I would argue that this non-support is a benefit since it means that server operators can't simply pick \texttt{h2c} for their own convenience, which ultimately makes the web in general more secure.

The HTTP/2 specification also defines stricter requirements for what ciphers clients and servers are allowed to use within TLS\@. It has a minimum version requirement of TLS 1.2, which is negligible in impact since around 90\% of TLS communication already uses this~\cite{sslpulse}. The specification also defines a cipher suite blacklist~\cite[\S 9.2.2]{h2}, which prevents servers from using some ciphers that are deemed to have inadequate insecurity. This blacklist is unfortunately a very tough requirement to meet, which causes some HTTP/2 servers to ignore this list entirely. I have also experienced issues with TLS compatibility when connecting to my own web server from some devices. So overall these additional TLS requirements do not do much to improve HTTP/2's security.

The predecessor to HTTP/2, called `SPDY', served as the basis for the HTTP/2 specification until its official standardisation in 2015. One of the major changes between SPDY and HTTP/2 is the header compression mechanism that is used. SPDY used an algorithm that was later discovered to be vulnerable to the `CRIME' exploit (Compression Ratio Info\hyp{}leak Made Easy)~\cite{crime}, which is essentially a chosen\hyp{}plaintext attack\footnote{This involves an attacker guessing the contents of an encrypted message, and working backwards to derive the encryption keys in order to read all encrypted messages that are sent.}. HTTP/2 mitigates this issue by using a different header compression algorithm which is not vulnerable to such attacks. HTTP/1 has no such vulnerability, since it does not use header compression. Additionally, due to the request and response multiplexing that HTTP/2 now mandates, this in itself increases the difficulty of a chosen\hyp{}plaintext attack (compared with HTTP/1.1), since network traffic is much less predictable. 

HTTP/2 incorporates a method of padding data (which is simply the insertion of random bytes) which is designed to further reduce the possibility of a chosen\hyp{}plaintext attack. However I would argue that this is of limited use, since this mechanism is already employed by TLS, and using padding bytes on top of this leads to an unnecessary increase in network bandwidth.

Finally, on a more practical note, the advent of a new protocol leads to a greater attack surface due to the implementation of new software. The HTTP/1.1 security pitfalls are reasonably well known by developers and have been incrementally ironed out of software over the years. With HTTP/2, there is a greater possibility of programmer error simply because the software has not been around as long, so bugs are likely to exist in implementations. Inevitably over time this will improve, but it is certainly something to be wary of in the short term.
